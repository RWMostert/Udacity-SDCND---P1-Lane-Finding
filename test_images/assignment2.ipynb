{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CS741: Assignment 2: Exact Inference in Trees and Graphs\n",
    "## Dr. Hennie de Villiers - Computer Science - Stellenbosch University\n",
    "\n",
    "## Your name:\n",
    "## Your student number:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Part of this assignment was adapted from Prof. Johan du Preez at Electronic Engineering\n",
    "\n",
    "## Please note, this is the preliminary assignment, I will inform you of any changes to this by the end of the week. (This may include extra questions towards the end of the assignment, but the first portion should stay more or less the same)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This assignment builds on your previous assignment. At very least, you should have completed the `infer` method, because you will use this as a component of your inference (we will be using Shafer-Shenoy message passing, which is basically `infer` being used on subportions of the joint distribution, rather than the entire joint distribution). We start by declaring every utility function from the last assignment, note that you have to fill in your version of the `infer` method. Also note that we are changing all occurences of `cpd` in identifiers to `factor`, because that is actually more correct when we are dealing with general graphical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Burglar Network: Setting up variables and factors\n",
    "\n",
    "As in the previous assignment, you will use the Burglar network to test out your code. In this section, we just repeat the definitions we used in the previous assignment. In the subsequent section, you will implement the portions of code needed to represent the Burglar network as a cluster graph. So, if you finished the first assignment, you can safely skip the current section (it is repeated here for clarity), and move on to the subsequent section.\n",
    "\n",
    "We are now going to learn more about multidimensional arrays (tensors) in Theano by implementing some basic inference tasks. Consider representing the conditional probability $P(A|B,E)$ from the \"Alarm\" problem from Chapter 3. The Numpy array representing this is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_a_given_be = np.zeros((2,2,2),dtype=theano.config.floatX)\n",
    "p_a_given_be[1,0,0] = 0.0001 # P(A=1|B=0,E=0)\n",
    "p_a_given_be[1,0,1] = 0.99 # P(A=1|B=0,E=0)\n",
    "p_a_given_be[1,1,0] = 0.99 # P(A=1|B=0,E=0)\n",
    "p_a_given_be[1,1,1] = 0.9999 # P(A=1|B=0,E=0)\n",
    "p_a_given_be[0,:,:] = 1 - p_a_given_be[1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, $P(R|E)$, $P(E)$ and $P(B)$ are given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_r_given_e = np.zeros((2,2),dtype=theano.config.floatX)\n",
    "p_r_given_e[1,0] = 0.0\n",
    "p_r_given_e[1,1] = 1.0\n",
    "p_r_given_e[0,:] = 1 - p_r_given_e[1,:]\n",
    "\n",
    "p_e = np.zeros((2,),dtype=theano.config.floatX)\n",
    "p_e[1] = 0.000001\n",
    "p_e[0] = 1 - p_e[1]\n",
    "\n",
    "p_b = np.zeros((2,),dtype=theano.config.floatX)\n",
    "p_b[1] = 0.01\n",
    "p_b[0] = 1 - p_b[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define state variables for each of the alarm problem's variables. They are 64-bit integer scalars, so we use the `T.lscalar` constructor (`l` for `long`). Note we do something different here from last time. For each variable, we keep track of its theano variable, and its domain size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_variable(name, domain_size):\n",
    "    return (T.lscalar(name), domain_size)\n",
    "\n",
    "def theano_variable(variable):\n",
    "    return variable[0]\n",
    "\n",
    "def domain_size(variable):\n",
    "    return variable[1]\n",
    "\n",
    "alarm = make_variable(\"A\", 2)\n",
    "burglar = make_variable(\"B\", 2)\n",
    "earthquake = make_variable(\"E\", 2)\n",
    "radio = make_variable(\"R\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to variables, we do bookkeeping for factors as well. We keep both the potential table, as well as the variables that are bound to it. Note that, for efficiency, sometimes you would want to share a potential table between different potentials (which you can do by passing the same table to `make_factor`), but this isn't important for this particular tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_factor(potential_table, bound_variables):\n",
    "    #pot_shape = tuple(potential_table.shape.eval())\n",
    "    bound_variable_shape = tuple([domain_size(v) for v in bound_variables])\n",
    "    #assert(pot_shape == bound_variable_shape)\n",
    "    \n",
    "    return (potential_table, tuple(bound_variables))\n",
    "\n",
    "def factor_table(factor):\n",
    "    return factor[0]\n",
    "\n",
    "def factor_variables(factor):\n",
    "    return factor[1]\n",
    "\n",
    "def factor_shape(factor):\n",
    "    return tuple([domain_size(f) for f in factor_shape])\n",
    "\n",
    "alarm_factor = make_factor(theano.shared(p_a_given_be), (alarm, burglar, earthquake))\n",
    "radio_factor = make_factor(theano.shared(p_r_given_e), (radio, earthquake))\n",
    "burglar_factor = make_factor(theano.shared(p_b), (burglar,))\n",
    "earthquake_factor = make_factor(theano.shared(p_e), (earthquake,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Shafer-Shenoy get burgled\n",
    "\n",
    "Your `infer` method from the previous assignment can actually be used as the foundation for performing Shafer-Shenoy message passing on an arbitrary cluster graph/tree. Let us begin by applying Shafer-Shenoy message passing on the burglar network. One cluster tree corresponding to Burglar network has two cluster, one with variables $A,B,E$, the other with variables $E,R$. The sepset between the two variable clusters contains just $E$ (this is the intersection of the two cluster variable sets). Below we draw the cluster graph using the `pydot` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"57pt\" viewBox=\"0.00 0.00 211.53 56.62\" width=\"212pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(109.24 27.1725)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-109.24,29.4429 -109.24,-27.1725 102.29,-27.1725 102.29,29.4429 -109.24,29.4429\" stroke=\"none\"/>\n",
       "<!-- c0 -->\n",
       "<g class=\"node\" id=\"node1\"><title>c0</title>\n",
       "<ellipse cx=\"-71.4432\" cy=\"-2.27043\" fill=\"none\" rx=\"33.5952\" ry=\"18\" stroke=\"blue\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"-71.4432\" y=\"1.42957\">A,B,E</text>\n",
       "</g>\n",
       "<!-- s0 -->\n",
       "<g class=\"node\" id=\"node3\"><title>s0</title>\n",
       "<polygon fill=\"none\" points=\"27.1533,-10.5571 -26.8467,-10.5571 -26.8467,25.4429 27.1533,25.4429 27.1533,-10.5571\" stroke=\"red\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"0.153289\" y=\"11.1429\">E</text>\n",
       "</g>\n",
       "<!-- c0&#45;&#45;s0 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>c0--s0</title>\n",
       "<path d=\"M-38.5786,2.18825C-34.7555,2.70692 -30.8875,3.2317 -27.1505,3.73869\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- c1 -->\n",
       "<g class=\"node\" id=\"node2\"><title>c1</title>\n",
       "<ellipse cx=\"71.29\" cy=\"-5.1725\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"blue\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71.29\" y=\"-1.4725\">E,R</text>\n",
       "</g>\n",
       "<!-- c1&#45;&#45;s0 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>c1--s0</title>\n",
       "<path d=\"M44.8013,-0.474979C39.113,0.533794 33.0926,1.60145 27.3769,2.61508\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_cluster_graph(cluster_labels, sepset_labels, sepset_connections):\n",
    "    cluster_dot = pydot.Dot()\n",
    "    cluster_dot.set_type(\"graph\")\n",
    "    clusters = [pydot.Node(\"c\" + str(n)) for n in range(len(cluster_labels))]\n",
    "    for n, c in enumerate(clusters):\n",
    "        clusters[n].set_label(cluster_labels[n])\n",
    "        clusters[n].set_color(\"blue\")\n",
    "        cluster_dot.add_node(clusters[n])\n",
    "    sepsets = [pydot.Node(\"s\" + str(n)) for n in range(len(sepset_labels))]\n",
    "    for n, c in enumerate(sepsets):\n",
    "        sepsets[n].set_label(sepset_labels[n])\n",
    "        sepsets[n].set_color(\"red\")\n",
    "        sepsets[n].set_shape(\"rectangle\")\n",
    "        cluster_dot.add_node(sepsets[n])\n",
    "    for n, c in enumerate(sepset_connections):\n",
    "        c1, c2 = c\n",
    "        cluster_dot.add_edge(pydot.Edge(clusters[c1], sepsets[n]))\n",
    "        cluster_dot.add_edge(pydot.Edge(clusters[c2], sepsets[n]))\n",
    "    return SVG(cluster_dot.create_svg(prog='neato'))\n",
    "        \n",
    "draw_cluster_graph([\"A\\,B\\,E\",\"E\\,R\"],[\"E\"],[(0,1)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, for trying out Shafer-Shenoy propagation, we should make the graph more complex. Another, less efficient, but valid, cluster graph is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"311pt\" viewBox=\"0.00 0.00 295.64 310.88\" width=\"296pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(184.216 157.801)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-184.216,153.075 -184.216,-157.801 111.422,-157.801 111.422,153.075 -184.216,153.075\" stroke=\"none\"/>\n",
       "<!-- c0 -->\n",
       "<g class=\"node\" id=\"node1\"><title>c0</title>\n",
       "<ellipse cx=\"71.5047\" cy=\"-135.801\" fill=\"none\" rx=\"33.5952\" ry=\"18\" stroke=\"blue\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71.5047\" y=\"-132.101\">A,B,E</text>\n",
       "</g>\n",
       "<!-- s0 -->\n",
       "<g class=\"node\" id=\"node5\"><title>s0</title>\n",
       "<polygon fill=\"none\" points=\"64.9316,-87.478 10.9316,-87.478 10.9316,-51.478 64.9316,-51.478 64.9316,-87.478\" stroke=\"red\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"37.9316\" y=\"-65.778\">E</text>\n",
       "</g>\n",
       "<!-- c0&#45;&#45;s0 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>c0--s0</title>\n",
       "<path d=\"M62.6838,-118.375C57.8656,-108.857 51.9077,-97.0875 47.0446,-87.4806\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- c1 -->\n",
       "<g class=\"node\" id=\"node2\"><title>c1</title>\n",
       "<ellipse cx=\"0.26589\" cy=\"0.171601\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"blue\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"0.26589\" y=\"3.8716\">E,R</text>\n",
       "</g>\n",
       "<!-- c1&#45;&#45;s0 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>c1--s0</title>\n",
       "<path d=\"M9.57652,-17.0452C15.1535,-27.3578 22.2422,-40.466 27.9368,-50.996\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- s1 -->\n",
       "<g class=\"node\" id=\"node6\"><title>s1</title>\n",
       "<polygon fill=\"none\" points=\"68.975,49.4641 14.975,49.4641 14.975,85.4641 68.975,85.4641 68.975,49.4641\" stroke=\"red\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"41.975\" y=\"71.1641\">E</text>\n",
       "</g>\n",
       "<!-- c1&#45;&#45;s1 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>c1--s1</title>\n",
       "<path d=\"M10.7909,17.1523C16.8723,26.964 24.5217,39.3053 30.7223,49.3092\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- s2 -->\n",
       "<g class=\"node\" id=\"node7\"><title>s2</title>\n",
       "<polygon fill=\"none\" points=\"-51.8828,-15.3358 -105.883,-15.3358 -105.883,20.6642 -51.8828,20.6642 -51.8828,-15.3358\" stroke=\"red\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"-78.8828\" y=\"6.3642\">E,R</text>\n",
       "</g>\n",
       "<!-- c1&#45;&#45;s2 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>c1--s2</title>\n",
       "<path d=\"M-26.9726,1.02941C-35.0216,1.2829 -43.827,1.5602 -51.8622,1.81325\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- c2 -->\n",
       "<g class=\"node\" id=\"node3\"><title>c2</title>\n",
       "<ellipse cx=\"80.4216\" cy=\"131.075\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"blue\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.4216\" y=\"134.775\">E</text>\n",
       "</g>\n",
       "<!-- c2&#45;&#45;s1 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>c2--s1</title>\n",
       "<path d=\"M70.3202,114.362C64.9806,105.528 58.4187,94.6707 52.9537,85.6286\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- c3 -->\n",
       "<g class=\"node\" id=\"node4\"><title>c3</title>\n",
       "<ellipse cx=\"-153.216\" cy=\"3.90376\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"blue\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"-153.216\" y=\"7.60376\">E,R</text>\n",
       "</g>\n",
       "<!-- c3&#45;&#45;s2 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>c3--s2</title>\n",
       "<path d=\"M-125.959,3.44923C-119.495,3.34144 -112.6,3.22646 -106.136,3.11867\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_cluster_graph([\"A\\,B\\,E\",\"E\\,R\",\"E\",\"E\\,R\"],[\"E\",\"E\",\"E\\,R\"],[(0,1),(1,2),(1,3)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this is still a tree, so we can perform exact inference, only the central node now receives three messages, and there is one sepset with multiple variables along it. Suppose we attach the potentials $p(A|B,E)$ (`alarm_factor`) and $P(B)$ (`burglar_factor`) to the $A,B,E$ cluster, the potential $p(E)$ (`earthquake_factor`) to the $E$ cluster, and the $P(R|E)$ (`radio_factor`) to the outer $E,R$ cluster. Use your `infer` method from the last assignment to calculate the messages in both directions. \n",
    "\n",
    "For Shafer-Shenoy progagation, the rule for calculating a message over a sepset to another node, is that we multiply all the incoming messages to the source node (except the one coming in over the sepset we are currently considering) with any potentials at that node, and marginalize out any variables that are not in the sepset. Note that sometimes there may not be any other incoming messages at the source (this is true of leaf nodes), or there may not be a potential attached to a given node (in the above graph, this is true of the central node). In such cases, we simply multiply by $1$ as a placeholder.\n",
    "\n",
    "We can calculate the message going the $E$ node using the following calls to `infer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case where Radio=1, Alarm=1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-05a3baad4d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Case where Radio=1, Alarm=1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mfactor_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_er_outer_to_er_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mfactor_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_abe_to_er_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mfactor_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_er_inner_to_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0da3dc0acade>\u001b[0m in \u001b[0;36mfactor_table\u001b[0;34m(factor)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfactor_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfactor_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "def factor_reorder(factor, final_var_order):\n",
    "    table = factor_table(factor)\n",
    "    current_var_order = factor_variables(factor)\n",
    "    ordering = []\n",
    "    for v in final_var_order:\n",
    "        try:\n",
    "            idx = current_var_order.index(v)\n",
    "            ordering.append(idx)\n",
    "        except ValueError:\n",
    "            ordering.append(\"x\")\n",
    "    return make_factor(table.dimshuffle(ordering), final_var_order)\n",
    "\n",
    "def factor_product(factors, final_var_order):\n",
    "    final_shape = tuple([domain_size(v) for v in final_var_order])\n",
    "    ones = make_factor(T.ones(final_shape, theano.config.floatX), final_var_order)\n",
    "    reordered = [factor_reorder(factor, final_var_order) for factor in factors]\n",
    "    final_factors = [ones] + reordered\n",
    "    final_tables = [factor_table(f) for f in final_factors]\n",
    "    return make_factor(reduce(operator.mul, final_tables), final_var_order)\n",
    "\n",
    "def factor_marginalize(factor, marginalize_out):\n",
    "    bound_variables = factor_variables(factor)\n",
    "    axes_to_sum = [bound_variables.index(v) for v in marginalize_out]\n",
    "    final_vars = []\n",
    "    marginalize_set = set(marginalize_out)\n",
    "    for f in factor_variables(factor):\n",
    "        if (f not in marginalize_set):\n",
    "            final_vars.append(f)\n",
    "    return make_factor(T.sum(factor_table(factor),axis=axes_to_sum), final_vars) \n",
    "\n",
    "def factor_normalize(factor):\n",
    "    table = factor_table(factor)\n",
    "    return make_factor(table / T.sum(table), factor_variables(factor))\n",
    "\n",
    "def calc_message(source_factors, source_other_incoming_messages, sepset_vars):\n",
    "    assert(isinstance(source_factors,list))\n",
    "    assert(isinstance(source_other_incoming_messages,list))\n",
    "    assert(isinstance(sepset_vars,list))\n",
    "    # Collect all the factors at the node, as well as the incoming messages\n",
    "    \n",
    "    # Determine which variables must be marginalized over (so that just the sepset variables remain)\n",
    "    \n",
    "    # Reorder the variables, similar to the way you did for infer in the last tutorial.\n",
    "    \n",
    "    # Form the product of all the relevant factors and messages.\n",
    "    \n",
    "    # Marginalize out the dropped variables\n",
    "    \n",
    "    # Normalize the resulting message and return it\n",
    "    return None\n",
    "\n",
    "def calc_marginal(node_factors, incoming_messages, marginal_vars):\n",
    "    assert(isinstance(node_factors,list))\n",
    "    assert(isinstance(incoming_messages,list))\n",
    "    assert(isinstance(marginal_vars,list))\n",
    "    # Given the factors at the node, ALL the incoming messages, and the variables you'd like in the marginal,\n",
    "    # return the maginal. This should be just one line of code.\n",
    "    return None\n",
    "\n",
    "\n",
    "# calc-message does not allow explicit conditioning. Instead, we will fake this potentials that are zero everywhere\n",
    "# except at the constant value of the given variable. \n",
    "def conditioning_factor(conditioned_variable, value):\n",
    "    table = np.zeros((domain_size(conditioned_variable),), dtype = theano.config.floatX)\n",
    "    table[value] = 1.0\n",
    "    table = theano.shared(table)\n",
    "    return make_factor(table, (conditioned_variable,))\n",
    "    \n",
    "def recondition(conditioning_factor, new_value):\n",
    "    conditioned_variable = factor_variables(conditioning_factor)[0]\n",
    "    table = np.zeros((domain_size(conditioned_variable),), dtype = theano.config.floatX)\n",
    "    table[new_value] = 1.0\n",
    "    theano_table = factor_table(conditioning_factor)\n",
    "    theano_table.set_value(table)\n",
    "\n",
    "def reset_condition(conditioning_factor):\n",
    "    conditioned_variable = factor_variables(conditioning_factor)[0]\n",
    "    table = np.ones((domain_size(conditioned_variable),), dtype = theano.config.floatX) / domain_size(conditioned_variable)\n",
    "    theano_table = factor_table(conditioning_factor)\n",
    "    theano_table.set_value(table)\n",
    "\n",
    "    \n",
    "radio_conditioner = conditioning_factor(radio, 1)    \n",
    "alarm_conditioner = conditioning_factor(alarm, 1)    \n",
    "\n",
    "er_outer_factors = [radio_factor, radio_conditioner]\n",
    "abe_factors = [alarm_factor, burglar_factor, alarm_conditioner]\n",
    "er_inner_factors = []\n",
    "e_factors = [earthquake_factor]\n",
    "\n",
    "message_er_outer_to_er_inner = calc_message(er_outer_factors, [], [earthquake,radio])\n",
    "message_abe_to_er_inner = calc_message(abe_factors, [], [earthquake])\n",
    "message_er_inner_to_e = calc_message(er_inner_factors,[message_er_outer_to_er_inner, message_abe_to_er_inner], [earthquake])\n",
    "marginal_at_e = calc_marginal(e_factors, [message_er_inner_to_e], [earthquake])\n",
    "\n",
    "print \"Case where Radio=1, Alarm=1\"\n",
    "print factor_table(message_er_outer_to_er_inner).eval()\n",
    "print factor_table(message_abe_to_er_inner).eval()\n",
    "print factor_table(message_er_inner_to_e).eval()\n",
    "print factor_table(marginal_at_e).eval()\n",
    "\n",
    "recondition(radio_conditioner, 0)\n",
    "print \"\\nCase where Radio=0, Alarm=1\"\n",
    "print factor_table(message_er_outer_to_er_inner).eval()\n",
    "print factor_table(message_abe_to_er_inner).eval()\n",
    "print factor_table(message_er_inner_to_e).eval()\n",
    "print factor_table(marginal_at_e).eval()\n",
    "\n",
    "reset_condition(radio_conditioner)\n",
    "print \"\\nCase where Alarm=1 (no knowledge of radio either way)\"\n",
    "print factor_table(message_er_outer_to_er_inner).eval()\n",
    "print factor_table(message_abe_to_er_inner).eval()\n",
    "print factor_table(message_er_inner_to_e).eval()\n",
    "print factor_table(marginal_at_e).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Now, calculate the messages needed to determine whether or not there is a burglar, and obtain the marginal over the Burglar variable.\n",
    "* If the alarm has sounded, but we have no evidence regarding whether or not there was a radio report. Recall your answer will be about $p(B|A=1)\\approx 0.99$.\n",
    "* If the alarm has sounded and there is a radio report.  Recall your answer will be about $p(B=1|A=1,R=1)\\approx 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional comments and investigation can be made here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Hamming Codes\n",
    "\n",
    "### Background (from last assignment):\n",
    "The Hamming $(7,4)$ code extends a 4 bit input sequence with a further 3 parity check bits to result in a 7 bit sequence to transmit. This provides redundancy that allows automatic correction of any one wrongly received bit. Figure 1 describes the coding stage of a Hamming $(7,4)$ code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "![Encoder](encode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first four bits $b_1 \\dots b_4$ represents the actual information we want to transmit. $\\phi_{c_1} \\dots \\phi_{c_3}$ are the (even) parity checkers. Bits $b_5 \\dots b_7$ are check bits to allow error correction – for a given $b_1\\dots b_4$ we choose them to result in an even total parity for all the bits connected to a common $\\phi_{c_i}$. For example, inputs $0111$ are transmitted as $0111010$. As an aside, note that if we should implement $\\phi_{c_i}$, as potentials as we do for the decoding stage below, we can also unambiguously obtain $b_5 \\dots b_7$ by finding its joint distribution given the observed $b_1 \\dots b_4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decoder](decode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2 is a factor graph describing the decoding process.  The sequence $r_1 \\dots r_7$ describes the received\n",
    "bits/signal values.  The variables $b_1 \\dots b_7$ are the decoded binary bit sequence.  We can consider two cases:\n",
    "\n",
    "- Hard decision: $r_1 \\dots r_7$ are already binarised:  In this case the factors/potentials $\\phi_{r_i}$ simply describe how likely it is that the received $r_i$ matches the transmitted $b_i$, i.e.  a discrete table giving\n",
    "potentials for the four allocations of the variables $(r_i; b_i)$.\n",
    "- Soft decision: $r_1 \\dots r_7$ are the actual continuous pre-binarised received values:  In this case the\n",
    "factors/potentials $\\phi_{r_i}$ can be two (continuous) Gaussian pdfs for $r_i$ conditioned on whether the\n",
    "transmitted value ($b_i$) was a zero or one.  The Gaussian means can be 0 and 1, while the standard\n",
    "deviation for both cases can be set at 0.25.\n",
    "\n",
    "The parity check factors/potentials $\\phi_{c_i}$ takes on values zero or one based on whether its four inputs has\n",
    "uneven or even parity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background (new): Cluster graph\n",
    "\n",
    "The *encoder* Markov network (the bottom part of the decoder network) is given by:\n",
    "\n",
    "![Decoder Markov network](hamming_markov.png)\n",
    "\n",
    "We can convert this into a Junction tree by using the variable elimination order $b_5$, $b_6$, $b_7$, $b_1$, $b_2$, $b_4$, $b_3$, which results in a cluster graph for the encoder network as below (verify this for yourself!):\n",
    "\n",
    "![Encoder](hamming_cluster_graph.png)\n",
    "\n",
    "Note that this is the *decoder* network (we have simply asses $r_n$ to the clusters at the top).\n",
    "\n",
    "### Question 2.1\n",
    "\n",
    "Apply the Shafer-Shenoy message passing you used in the previous question to the Junction Tree created here for the *HARD*-decoding case (assume a bit has a 5% chance of being mistransmitted). In other words, use a proper message-passing schedule that only sends a message when all the incoming messages it relies on are finalised. And do only one pass in each direction of each link. \n",
    "* Use this to calculate the marginals for each of the transmitted bits $b_n$, conditioned on the received bits $r_n$ (where $r_n$ is 0 or 1). \n",
    "* Assume that the values of $b_n$ that result in the maximum values at their marginals $p(b_n)$ are the transmitted bits, and determine whether this results in correct error correction in all cases where there is 0 or 1 error. Note that, in general, maximizing the marginals seperately is *NOT* equivalent to maximizing the joint. For that, we need to implement the max-product algorithm, but we will settle for this approximation here.\n",
    "\n",
    "Hints: \n",
    "* First determine all the potentials in the problem. Define each of them.\n",
    "* Then determine to which cluster each potential attaches.\n",
    "* Message passing starts at the leaves, so work from there downwards, then back upwards once you've reached the bottom of the graph.\n",
    "* Remember, you can introduce evidence using the conditioning factors. You can use this, as well as theano.function, to do the inference in one shot without rebuilding the network each time.\n",
    "* Be careful on the upward pass towards the top nodes, since some of the downward messages are reused on this pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define your network here in a reusable format so that ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ... in this block you can do your analysis, without having to have Theano rebuild the network each time. Use conditioning potentials for this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2: Discussion\n",
    "If the decoding does not successfully decode all cases with 0 or 1 error, why not? Can you motivate why the specific cases that fail follow from the junction tree and the potentials in question? If the decoding is perfect, discuss why the potentials and the junction tree structure imply this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional comments\n",
    "\n",
    "Add any additional comments or investigation you perform below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
